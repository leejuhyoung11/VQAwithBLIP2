{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import yaml, sys\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, Blip2Model, BlipImageProcessor, \n",
    "    AutoTokenizer, BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "\n",
    "# 주요 디렉토리 경로 정의\n",
    "SRC_DIR = BASE_DIR / \"src\"\n",
    "CONFIG_DIR = BASE_DIR / \"configs\"\n",
    "OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
    "\n",
    "# src 폴더 import 경로에 추가\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# From src dir\n",
    "from model import BLIP2ForPhi, setup_model, select_train_params\n",
    "from dataset import ImageCaptioningDataset, get_datasets\n",
    "from trainer import CustomTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-06T22:31:55.077924Z",
     "iopub.status.busy": "2025-07-06T22:31:55.077357Z",
     "iopub.status.idle": "2025-07-06T22:31:55.081578Z",
     "shell.execute_reply": "2025-07-06T22:31:55.080865Z",
     "shell.execute_reply.started": "2025-07-06T22:31:55.077903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"TOKEN ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = CONFIG_DIR / \"config.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "model, image_processor, tokenizer = setup_model(config)\n",
    "num_trainable_params = select_train_params(model, language_model=False)\n",
    "\n",
    "print(f\"training {num_trainable_params} params...\")\n",
    "print(f\"Preparing dataset...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset1, valid_dataset1, train_debug1, valid_debug1 = get_datasets(config['dataset']['cocoCaption'], config, image_processor, tokenizer)\n",
    "train_dataset2, valid_dataset2, train_debug2, valid_debug2 = get_datasets(config['dataset']['flickr'], config, image_processor, tokenizer)\n",
    "train_dataset3, valid_dataset3, train_debug3, valid_debug3 = get_datasets(config['dataset']['llava'], config, image_processor, tokenizer)\n",
    "\n",
    "concat_train_dataset = ConcatDataset([train_dataset1, train_dataset2])\n",
    "concat_valid_dataset = ConcatDataset([valid_dataset1, valid_dataset2])\n",
    "\n",
    "num_samples_to_train, num_samples_to_valid = int(len(concat_train_dataset)*0.1), int(len(concat_valid_dataset)*0.1)\n",
    "\n",
    "subset_of_train_dataset3 = train_dataset3.shuffle(seed=42).select(range(num_samples_to_train))\n",
    "subset_of_valid_dataset3 = valid_dataset3.shuffle(seed=42).select(range(num_samples_to_valid))\n",
    "\n",
    "final_train_dataset = ConcatDataset([concat_train_dataset, subset_of_train_dataset3])\n",
    "final_valid_dataset = ConcatDataset([concat_valid_dataset, subset_of_valid_dataset3])\n",
    "\n",
    "print(f\"Train Dataset length: {len(final_train_dataset)}, Valid Dataset length: {len(final_valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.AdamW(\n",
    "    trainable_params, \n",
    "    lr=float(config['training']['learning_rate']), \n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=final_train_dataset,\n",
    "        val_dataset=final_valid_dataset,\n",
    "        dataset_name='ImageCaptioning',\n",
    "        batch_size=config['training']['batch_size'],\n",
    "        save_dir=config['path']['save_dir'],\n",
    "        repo_id=config['hf']['repo_id']\n",
    "    )\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train(\n",
    "    num_epochs=config['training']['num_epochs'],\n",
    "    resume_from_checkpoint=config['path'].get('resume_from_checkpoint'),\n",
    ")\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 1. 모든 학습 코드를 담을 메인 함수 정의\n",
    "# ==========================================================\n",
    "def main():\n",
    "    # --- Imports ---\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    import yaml, sys\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from transformers import (\n",
    "        AutoModelForCausalLM, Blip2Model, BlipImageProcessor, \n",
    "        AutoTokenizer, BitsAndBytesConfig\n",
    "    )\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "    from datasets import load_dataset\n",
    "    from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "\n",
    "    # --- Path Setup (중요: 함수 안에서 경로 설정) ---\n",
    "    BASE_DIR = Path(\"..\").resolve()\n",
    "    SRC_DIR = BASE_DIR / \"src\"\n",
    "    CONFIG_DIR = BASE_DIR / \"configs\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
    "    \n",
    "    if str(SRC_DIR) not in sys.path:\n",
    "        sys.path.append(str(SRC_DIR))\n",
    "\n",
    "    # --- Custom Module Imports (중요: 함수 안에서 import) ---\n",
    "    from model import BLIP2ForPhi, setup_model, select_train_params\n",
    "    from dataset import ImageCaptioningDataset, get_datasets\n",
    "    from trainer import CustomTrainer\n",
    "\n",
    "    # --- Config & Token Setup ---\n",
    "    import os\n",
    "    os.environ[\"HF_TOKEN\"] = \"YOUR_TOKEN_HERE\" # 실제 토큰을 여기에 넣거나 환경 변수 사용\n",
    "    \n",
    "    config_path = CONFIG_DIR / \"config.yaml\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    # --- Model & Data Preparation ---\n",
    "    model, image_processor, tokenizer = setup_model(config)\n",
    "    num_trainable_params = select_train_params(model, language_model=False)\n",
    "    print(f\"training {num_trainable_params} params...\")\n",
    "    print(f\"Preparing dataset...\")\n",
    "\n",
    "    train_dataset1, valid_dataset1, _, _ = get_datasets(config['dataset']['cocoCaption'], config, image_processor, tokenizer)\n",
    "    train_dataset2, valid_dataset2, _, _ = get_datasets(config['dataset']['flickr'], config, image_processor, tokenizer)\n",
    "    train_dataset3, valid_dataset3, _, _ = get_datasets(config['dataset']['llava'], config, image_processor, tokenizer)\n",
    "\n",
    "    concat_train_dataset = ConcatDataset([train_dataset1, train_dataset2])\n",
    "    concat_valid_dataset = ConcatDataset([valid_dataset1, valid_dataset2])\n",
    "\n",
    "    num_samples_to_train = int(len(concat_train_dataset) * 0.1)\n",
    "    num_samples_to_valid = int(len(concat_valid_dataset) * 0.1)\n",
    "\n",
    "    subset_of_train_dataset3 = train_dataset3.shuffle(seed=42).select(range(num_samples_to_train))\n",
    "    subset_of_valid_dataset3 = valid_dataset3.shuffle(seed=42).select(range(num_samples_to_valid))\n",
    "\n",
    "    final_train_dataset = ConcatDataset([concat_train_dataset, subset_of_train_dataset3])\n",
    "    final_valid_dataset = ConcatDataset([concat_valid_dataset, subset_of_valid_dataset3])\n",
    "    \n",
    "    print(f\"Train Dataset length: {len(final_train_dataset)}, Valid Dataset length: {len(final_valid_dataset)}\")\n",
    "\n",
    "    # --- Optimizer & Trainer Setup ---\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        trainable_params, \n",
    "        lr=float(config['training']['learning_rate']), \n",
    "        weight_decay=config['training']['weight_decay']\n",
    "    )\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=final_train_dataset,\n",
    "        val_dataset=final_valid_dataset,\n",
    "        dataset_name='ImageCaptioning',\n",
    "        batch_size=config['training']['batch_size'],\n",
    "        save_dir=config['path']['save_dir'],\n",
    "        repo_id=config['hf']['repo_id']\n",
    "    )\n",
    "\n",
    "    # --- Start Training ---\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train(\n",
    "        num_epochs=config['training']['num_epochs'],\n",
    "        resume_from_checkpoint=config['path'].get('resume_from_checkpoint'),\n",
    "    )\n",
    "    print(\"Training finished!\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 2. notebook_launcher로 위에서 정의한 main 함수 실행\n",
    "# ==========================================================\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "# 2개의 GPU에서 main 함수를 실행합니다.\n",
    "notebook_launcher(main, num_processes=2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
