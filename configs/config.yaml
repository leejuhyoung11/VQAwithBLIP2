# -- Directories --
path:
  train_csv_path: "/path/to/train.csv"
  eval_csv_path: "/path/to/eval.csv"
  image_dir: None
  save_dir: 
    stage1: "../outputs/checkpoints"
    stage2: "../outputs/checkpoints"
    stage3: "../outputs/checkpoints"
    stage4: "../outputs/checkpoints"
  instruct_df: "../datasets/llava_instruct_150k.json"
  coco2014: "../datasets/train2014"
  instruct_visual7w: "../datasets/dataset_v7w_telling.json"
  visual7w: "../datasets/images"
  stage1_checkpoint: "../outputs/checkpoints/ImageCaptioning-stage1/epoch_12/checkpoint_epoch12.pt"
  stage2_checkpoint: "../outputs/checkpoints/ImageCaptioning-stage2/epoch_3/checkpoint_epoch3.pt"
  stage3_checkpoint: "../outputs/checkpoints/ImageCaptioning-stage3/epoch_3/checkpoint_epoch3.pt"
  resume_from_checkpoint: null # Or "/path/to/checkpoint.pt"

# -- Datasets --
dataset:
  cocoCaption: "lmms-lab/COCO-Caption" # Only use 'val'
  flickr: "lmms-lab/flickr30k"
  textCaps: "lmms-lab/TextCaps"
  llava: "lmms-lab/LLaVA-ReCap-558K"
  vqav2: "lmms-lab/VQAv2"
  gqa: ["lmms-lab/GQA", ["train_balanced_images", "train_balanced_instructions"]] # train_balanced_instructions, train_balanced_images
  llavaNext: "lmms-lab/LLaVA-NeXT-Data"
  instruct150: "liuhaotian/LLaVA-Instruct-150K"
  aokvqa: "HuggingFaceM4/A-OKVQA"
  okvqa: "lmms-lab/OK-VQA"
  visual7w: "nimapourjafar/mm_visual7w"


# -- Model Configuration --
model:
  vision_model_name: "Salesforce/blip2-opt-2.7b"
  llm_name:  "microsoft/phi-1_5"
  num_query_tokens: 32
  lora:
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    target_modules: ["q_proj", "k_proj", "v_proj", "dense", "fc1", "fc2"]
    bias: "none"
    task_type: "CAUSAL_LM"

# -- Training arguments --
training:
  stage1:
    num_epochs: 50
    batch_size: 32
    learning_rate: 2e-5
    weight_decay: 0.01
    warmup_ratio: 0.1
    tokenizer_max_length: 180
  stage2:
    num_epochs: 50
    batch_size: 32
    learning_rate: 1e-5
    weight_decay: 0.01
    warmup_ratio: 0.1
    tokenizer_max_length: 512
  stage3:
    num_epochs: 12
    batch_size: 32
    learning_rate: 1e-5
    weight_decay: 0.01
    warmup_ratio: 0.1
    tokenizer_max_length: 256
  stage4:
    num_epochs: 10
    batch_size: 32
    learning_rate: 1e-5
    weight_decay: 0.01
    warmup_ratio: 0.1
    tokenizer_max_length: 256

hf:
  repo_id: 'DRPARKSTREET/BLIP2_PHI1.5'
